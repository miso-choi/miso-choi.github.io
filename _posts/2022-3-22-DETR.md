---
layout: post
title: DETR : End-to-End Object Detection with Transformers 논문 구현 - Intro
---


# DETR : End-to-End Object Detection with Transformers (Facebook AI, ECCV, 2020)
- DETR는 Object Detection을 하나의 direct set prediction으로 보여준 새로운 구조의 모델입니다.   
- Object Detection이란, 이미지나 동영상에서 관심있는 객체의 bounding box를 찾아내고 각각의 category label을 예측하는 기술입니다.    
- 즉, Object Detection 모델은 여러 물체에 대해 class를 예측하는 Classification과 각 물체가 어디에 있는지를 찾아내는 Localization을 수행합니다.  
- 전통적인 많은 detector들은 이 과정들을 region proposal, anchors, window centers 등의 방법들을 사용해야 하는 복잡한 pipeline을 갖고 있는 반면, DETR는 다음의 두 가지 과정으로 direct set prediction을 수행합니다.
1) Set-based global loss
2) Transformer Encoder-Decoder architecture

![image](https://user-images.githubusercontent.com/78155086/159425203-c2beb19e-915a-46c3-9195-fb410dc84e9e.png)
DETR의 전반적인 구조도입니다. 이미지를 입력으로 받아 CNN으로 feature를 추출한 뒤, transformer의 encoder-decoder 구조를 이용하여 여러 객체들의 bounding box와 class를 예측합니다. DETR는 고정적으로 한 이미지당 100개의 객체를 예측합니다(no object 포함). Set-prediction loss는 여러 객체들의 Ground-truth와 예측된 값 사이의 최적의 이분 매칭(optimal bipartite matching)을 해주고, 각각의 pair에서 class와 bounding box의 차이를 최소화합니다.


---------------------------------     


이번 포스팅은 논문 구현에 초점을 맞추었으니 논문에 대한 자세한 설명은 다른 포스팅을 통해 해보겠습니다.    
DETR의 코드는 다음과 같은 단계로 분석해보았습니다.    
제목을 클릭하시면 다른 포스팅으로 이동할 수 있습니다.

## 논문 구현 단계
#### [1. DETR 깃허브에서 제공하는 Pytorch training code 분석 및 실행](https://miso-choi.github.io/2022-3-22-DETR-1/)
#### 2. DETR raw code 분석
#### 3. DETR 모델 코드를 google drive에 clone하고 COCO 데이터 다운받아 training 실행
#### 4. DETR를 활용한 새로운 모델 구상하여 코드 작업 후 training 성공


